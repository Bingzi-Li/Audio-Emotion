{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_pandas\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import warnings\n",
    "# ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, n, feature, aug=False):\n",
    "    X = np.empty(shape=(df.shape[0], n, 216, 1))\n",
    "    input_length = sampling_rate * audio_duration\n",
    "\n",
    "    cnt = 0\n",
    "    for fname in tqdm(df.path):\n",
    "        file_path = fname\n",
    "        data, _ = librosa.load(file_path, sr=sampling_rate, res_type=\"kaiser_fast\", duration=2.5, offset=0.5\n",
    "                               )\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, int(input_length) -\n",
    "                                 len(data) - offset), \"constant\")\n",
    "\n",
    "        # Augmentation?\n",
    "        if aug:\n",
    "            data = speedNpitch(data)\n",
    "\n",
    "        # which feature?\n",
    "        if feature == 'MFCC':\n",
    "            # MFCC extraction\n",
    "            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "            MFCC = np.expand_dims(MFCC, axis=-1)\n",
    "            X[cnt, ] = MFCC\n",
    "\n",
    "        elif feature == 'Log':\n",
    "            # Log-melspectogram\n",
    "            melspec = librosa.feature.melspectrogram(data, n_mels=n_melspec)\n",
    "            logspec = librosa.amplitude_to_db(melspec)\n",
    "            logspec = np.expand_dims(logspec, axis=-1)\n",
    "            X[cnt, ] = logspec\n",
    "        else:\n",
    "            raise Exception('The feature extraction method is undefined.')\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8690"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pd.read_csv(\"../metadata/Data_path.csv\")\n",
    "ref.sample(n=5)\n",
    "len(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8690/8690 [03:25<00:00, 42.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8690"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate=44100\n",
    "audio_duration=2.5\n",
    "n_mfcc = 30\n",
    "mfcc = prepare_data(ref, n = n_mfcc, feature='MFCC')\n",
    "len(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8690, 30, 216, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../processed_data/'):\n",
    "    os.mkdir('../processed_data/')\n",
    "with open(\"../processed_data/mfcc.npy\", \"wb\") as f:\n",
    "    np.save(file=f, arr=mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8690/8690 [03:11<00:00, 45.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Log-melspectogram\n",
    "sampling_rate=44100\n",
    "audio_duration=2.5\n",
    "n_melspec = 60\n",
    "mel_specgram = prepare_data(ref,  n = n_melspec, feature='Log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8690, 60, 216, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_specgram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../processed_data/'):\n",
    "    os.mkdir('../processed_data/')\n",
    "with open(\"../processed_data/logspec.npy\", \"wb\") as f:\n",
    "    np.save(file=f, arr=mel_specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = pd.read_csv(\"../metadata/Data_path.csv\")\n",
    "ref = ref.loc[ref['source'] == 'RAVDESS']\n",
    "ref.sample(n=5)\n",
    "len(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1248/1248 [00:37<00:00, 33.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 30, 216, 1)\n"
     ]
    }
   ],
   "source": [
    "sampling_rate=44100\n",
    "audio_duration=2.5\n",
    "n_mfcc = 30\n",
    "mfcc = prepare_data(ref, n = n_mfcc, feature='MFCC')\n",
    "print(mfcc.shape)\n",
    "\n",
    "if not os.path.exists('../processed_data/'):\n",
    "    os.mkdir('../processed_data/')\n",
    "with open(\"../processed_data/ravdess-mfcc.npy\", \"wb\") as f:\n",
    "    np.save(file=f, arr=mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
